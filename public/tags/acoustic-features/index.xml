<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>acoustic features on Coded bioacoustics</title>
    <link>marce10.github.io/coded_bioacustics/tags/acoustic-features/</link>
    <description>Recent content in acoustic features on Coded bioacoustics</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sat, 12 Jan 2019 00:00:00 +0000</lastBuildDate>
    <atom:link href="marce10.github.io/coded_bioacustics/tags/acoustic-features/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Compare signals from selection tables to a set of templates using cross-correlation</title>
      <link>marce10.github.io/coded_bioacustics/post/2019-01-12-selection_table_vs_template_xcorr/</link>
      <pubDate>Sat, 12 Jan 2019 00:00:00 +0000</pubDate>
      <guid>marce10.github.io/coded_bioacustics/post/2019-01-12-selection_table_vs_template_xcorr/</guid>
      <description>I got the following question about cross-correlation:&#xA;&amp;ldquo;We would like to compare every call within a selection table to a template of each owl, and get peak correlation coefficients on each call separately&amp;rdquo;&#xA;One way to do this would be putting the unidentified and template signals together into a single selection table, and then running cross-correlation. However, this will also compare all unidentified signals against each other, which can be very inefficient.</description>
    </item>
    <item>
      <title>Choosing the right method for measuring acoustic signal structure</title>
      <link>marce10.github.io/coded_bioacustics/post/2017-02-17-choosing-the-right-method-for-measuring-acoustic-signal-structure/</link>
      <pubDate>Fri, 17 Feb 2017 00:00:00 +0000</pubDate>
      <guid>marce10.github.io/coded_bioacustics/post/2017-02-17-choosing-the-right-method-for-measuring-acoustic-signal-structure/</guid>
      <description>Bioacoustic research relies on quantifying the structure of acoustic` signals and comparing that structure across behavioral/ecological contexts, groups or species. However, measuring signal structure in a way that fully accounts for the variation in the signals could be a tricky task. Some of the differences that are apparent by visual inspection of spectrograms might not be picked up by some analyses. Hence, choosing the most appropriate analytical approach is a critical step.</description>
    </item>
    <item>
      <title>Frequency range detection from spectrum</title>
      <link>marce10.github.io/coded_bioacustics/post/2018-06-29-frequency_range_detection_from_spectrum/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>marce10.github.io/coded_bioacustics/post/2018-06-29-frequency_range_detection_from_spectrum/</guid>
      <description>We are often interested in getting the frequency range of acoustic signals, either because we have specific predictions about its variation or simply because we want to measure other stuff within that range. Measuring frequency range is typically done by drawing boxes in Raven/Avisoft/Syrinx. An alternative way, and potentially less subjective, is to infer the range from the energy distribution in the frequency domain applying amplitude thresholds on spectrums. I have added two new functions to warbleR that do exactly that:</description>
    </item>
    <item>
      <title>Potential issues of the &#39;spectral parameters/PCA&#39; approach</title>
      <link>marce10.github.io/coded_bioacustics/post/2018-07-04-issues_spectral_parameters-pca/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>marce10.github.io/coded_bioacustics/post/2018-07-04-issues_spectral_parameters-pca/</guid>
      <description>Somehow measuring a bunch of spectral/temporal parameters and then reducing its dimensionality using principal component analysis has become the standard procedure when looking at variation in signal structure (i.e. measuring acoustic space), particularly in behavioral ecology and comparative bioacoustics. In most cases the approach is used without any kind of ground-truthing that can help validate the analysis. Given the complexity of animal acoustic signals, the approach could miss key signal features.</description>
    </item>
    <item>
      <title>Song similarity using dynamic time warping</title>
      <link>marce10.github.io/coded_bioacustics/post/2016-09-12-similarity_of_acoustic_signals_with_dynamic_time_warping_dtw/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>marce10.github.io/coded_bioacustics/post/2016-09-12-similarity_of_acoustic_signals_with_dynamic_time_warping_dtw/</guid>
      <description>Here I show how to use the dfDTW function in warbleR to compare acoustics signals using dynamic time warping (DTW).&#xA;First load these packages (if not installed the code will install it):&#xA;x&amp;lt;-c(&amp;#34;vegan&amp;#34;, &amp;#34;warbleR&amp;#34;) A &amp;lt;- lapply(x, function(y) { if(!y %in% installed.packages()[,&amp;#34;Package&amp;#34;]) install.packages(y) require(y, character.only = T) }) and load example data from warbleR&#xA;# optional, save it in a temporal folder # setwd(tempdir()) data(list = c( &amp;#34;Phae.long1&amp;#34;, &amp;#34;Phae.long2&amp;#34;,&amp;#34;Phae.long3&amp;#34;, &amp;#34;Phae.long4&amp;#34;,&amp;#34;selec.table&amp;#34;)) writeWave(Phae.</description>
    </item>
  </channel>
</rss>
